<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sohail Khan</title>

    <meta name="author" content="Sohail Khan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body style="background-color: #F0EDE6;">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sohail Khan
                </p>
                <p>I'm a PhD candidate at <a href="https://mediafutures.no/">SFI-MediaFutures</a>, University of Bergen, Norway .
                </p>
                <p>
                  Previously I was a research assistant at  <a href="https://mbzuai.ac.ae/">MBZUAI</a>, Abu Dhabi, UAE, where I worked on video analysis and <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">deepfake detection</a>. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:sohailahmedkhan173@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/KhanCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=clIS5CsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/sohail-ahmed-khan-97794b175/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/sohailahmedkhan">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/sak2.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/sak2.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Selected Articles</h2>
                <!-- <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p> -->
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                  <source src="images/r2r.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/r2r.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function r2r_start() {
                    document.getElementById('r2r_image').style.opacity = "1";
                  }

                  function r2r_stop() {
                    document.getElementById('r2r_image').style.opacity = "0";
                  }
                  r2r_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3652583.3658035">
                  <span class="papertitle">CLIPping the Deception: Adapting Vision-Language Models for Universal Deepfake Detection
                  </span>
                </a>
                <br>
                <strong>Sohail Ahmed Khan</strong>, 
                <a href="https://dnductien.github.io/">Duc-Tien Dang-Nguyen</a>
                <br>
                <em>ACM ICMR</em>, 2024 &nbsp
                <br>
                <a href="https://github.com/sfimediafutures/CLIPping-the-Deception">code</a>
                /
                <a href="https://dl.acm.org/doi/abs/10.1145/3652583.3658035">paper</a>
                <p></p>
                <p style="text-align: justify;">
                  We investigate the use of pre-trained vision-language models (VLMs), specifically CLIP, for universal deepfake detection using a single dataset (ProGAN) for adaptation. Unlike prior work that disregards CLIP’s textual component, the authors demonstrate that retaining it significantly boosts performance. Their lightweight Prompt Tuning approach surpasses the previous state-of-the-art by notable margins while using significantly less training data, and proves effective across 21 diverse deepfake datasets.
                </p>
              </td>
            </tr>
            
            
            <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/cat4d.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/cat4d.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function cat4d_start() {
                    document.getElementById('cat4d_image').style.opacity = "1";
                  }

                  function cat4d_stop() {
                    document.getElementById('cat4d_image').style.opacity = "0";
                  }
                  cat4d_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">
              <span class="papertitle">Video Transformer for Deepfake Detection with Incremental Learning
              </span>
                </a>
                <br>
                <strong>Sohail Ahmed Khan</strong>,
                <a href="https://dai-hang.github.io/">Hang Dai</a>
                <br>
                <em>ACM Multimedia</em>, 2021 &nbsp
                <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                <br>
                <a href="https://github.com/sohailahmedkhan/Video-Transformer-for-Deepfake-Detection">code</a>
                /
                <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">paper</a>
                <p></p>
                <p style="text-align: justify;">
                  We introduce a novel video transformer model with incremental learning for detecting deepfake videos. It leverages 3D face reconstruction to generate UV texture maps from input face images, using both the textures and original images to extract rich features like pose and facial movements. The model, fine-tuned through incremental learning, achieves state-of-the-art performance across multiple public deepfake datasets.
                </p>
              </td>
            </tr>
            
            <tr bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <!-- <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/cat4d.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div> -->
                  <img src='images/cat4d.jpg' width="160">
                </div>
                <!-- <script type="text/javascript">
                  function cat4d_start() {
                    document.getElementById('cat4d_image').style.opacity = "1";
                  }

                  function cat4d_stop() {
                    document.getElementById('cat4d_image').style.opacity = "0";
                  }
                  cat4d_stop()
                </script> -->
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">
                  <span class="papertitle">Debunking War Information Disorder: A Case Study in Assessing the Use of Multimedia Verification Tools
                  </span>
                </a>
                <br>
                <strong>Sohail Ahmed Khan</strong>,
                <a href="https://dai-hang.github.io/">Hang Dai</a>
                <br>
                <em>ACM Multimedia</em>, 2021 &nbsp
                <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                <br>
                <a href="https://github.com/sohailahmedkhan/Video-Transformer-for-Deepfake-Detection">code</a>
                /
                <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">paper</a>
                <p></p>
                <p style="text-align: justify;">
                  We explore the use of computational tools and Open-source Intelligence (OSINT) methods for verifying online multimedia content amid the wars in Ukraine and Gaza. By analyzing the workflows of fact-checkers at the Norwegian organization Faktisk, the study highlights the effectiveness of AI, geolocation, internet archives, and social media monitoring in verifying information. It also discusses both the potential and limitations of current technologies, offering insights for the future development of digital verification tools.
                </p>
              </td>
            </tr>

          </tbody></table>







          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <br>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Journal Articles</h2>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                <source src="images/r2r.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/r2r.jpg' width=100%>
              </div>
              <!-- <script type="text/javascript">
                function r2r_start() {
                  document.getElementById('r2r_image').style.opacity = "1";
                }

                function r2r_stop() {
                  document.getElementById('r2r_image').style.opacity = "0";
                }
                r2r_stop()
              </script> -->
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24970">
                <span class="papertitle">Debunking War Information Disorder: A Case Study in Assessing the Use of Multimedia Verification Tools
                </span>
              </a>
              <br>
              <strong>Sohail Ahmed Khan</strong>,
              <a href="#">Laurence Dierickx</a>,
              <a href="#">Jan‐Gunnar Furuly</a>,
              <a href="#">Henrik Brattli Vold</a>,
              <a href="#">Rano Tahseen</a>,
              <a href="#">Carl‐Gustav Linden</a>,
              <a href="https://dnductien.github.io/">Duc-Tien Dang-Nguyen</a>
              <br>
              <em>JASIST</em>, 2024 &nbsp
              <br>
              <a href="https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24970">paper</a>
              <p></p>
              <p style="text-align: justify;">
                We explore the use of computational tools and Open-source Intelligence (OSINT) methods for verifying online multimedia content amid the wars in Ukraine and Gaza. By analyzing the workflows of fact-checkers at the Norwegian organization Faktisk, the study highlights the effectiveness of AI, geolocation, internet archives, and social media monitoring in verifying information. It also discusses both the potential and limitations of current technologies, offering insights for the future development of digital verification tools.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cat4d.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/cat4d.jpg' width="160">
              </div>
              <!-- <script type="text/javascript">
                function cat4d_start() {
                  document.getElementById('cat4d_image').style.opacity = "1";
                }

                function cat4d_stop() {
                  document.getElementById('cat4d_image').style.opacity = "0";
                }
                cat4d_stop()
              </script> -->
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s10676-024-09801-6">
            <span class="papertitle">A Data-centric Approach for Ethical and Trustworthy AI in Journalism
            </span>
              </a>
              <br>
              <a href="#">Laurence Dierickx</a>,
              <a href="#">Andreas Lothe Opdahl</a>,
              <strong>Sohail Ahmed Khan</strong>,
              <a href="#">Carl-Gustav Lindén</a>,
              <a href="#">Diana Carolina Guerrero Rojas</a>
              <br>
              <em>Ethics and Information Technology</em>, 2024 &nbsp
              <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://link.springer.com/article/10.1007/s10676-024-09801-6">paper</a>
              <p></p>
              <p style="text-align: justify;">
                We propose a data quality assessment framework for the collection and pre-processing stages of machine learning, grounded in the journalistic principles of accuracy, fairness, and transparency. By emphasizing data quality over sheer quantity, the framework supports the shift toward data-centric AI, aiming to reduce errors, ensure consistent labeling, and incorporate journalistic expertise into AI workflows.
              </p>
            </td>
          </tr>

          <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cat4d.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/cat4d.jpg' width="160">
              </div>
              <!-- <script type="text/javascript">
                function cat4d_start() {
                  document.getElementById('cat4d_image').style.opacity = "1";
                }

                function cat4d_stop() {
                  document.getElementById('cat4d_image').style.opacity = "0";
                }
                cat4d_stop()
              </script> -->
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/iel7/6287639/10380310/10376174.pdf">
            <span class="papertitle">Deepfake Detection: Analyzing Model Generalization Across Architectures, Datasets, and Pre-Training Paradigms
            </span>
              </a>
              <br>
              <strong>Sohail Ahmed Khan</strong>,
              <a href="https://dnductien.github.io/">Duc-Tien Dang-Nguyen</a>
              <br>
              <em>IEEE Access</em>, 2023 &nbsp
              <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://ieeexplore.ieee.org/iel7/6287639/10380310/10376174.pdf">paper</a>
              <p></p>
              <p style="text-align: justify;">
                We investigate the generalization challenge in deepfake detection by evaluating various deep learning architectures, pre-training strategies, and datasets. Through comprehensive intra- and inter-dataset analyses across ten models and four benchmarks, the study finds that transformer-based models outperform CNNs and that datasets like FaceForensics++ and DFDC offer better generalization. Additionally, image augmentations are shown to enhance performance, especially for transformer models, while highlighting the trade-offs between model size, efficiency, and accuracy.
              </p>
            </td>
          </tr>

          <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cat4d.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/cat4d.jpg' width="160">
              </div>
              <!-- <script type="text/javascript">
                function cat4d_start() {
                  document.getElementById('cat4d_image').style.opacity = "1";
                }

                function cat4d_stop() {
                  document.getElementById('cat4d_image').style.opacity = "0";
                }
                cat4d_stop()
              </script> -->
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/iel7/6287639/6514899/10017287.pdf">
            <span class="papertitle">Visual User-Generated Content Verification in Journalism: An Overview
            </span>
              </a>
              <br>
              <strong>Sohail Ahmed Khan</strong>,
              <a href="#">Ghazaal Sheikhi</a>,
              <a href="#">Andreas L Opdahl</a>,
              <a href="#">Fazle Rabbi</a>,
              <a href="#">Sergej Stoppel</a>,
              <a href="https://www.christophtrattner.com/">Christoph Trattner</a>,
              <a href="https://dnductien.github.io/">Duc-Tien Dang-Nguyen</a>
              <br>
              <em>IEEE Access</em>, 2023 &nbsp
              <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://ieeexplore.ieee.org/iel7/6287639/6514899/10017287.pdf">paper</a>
              <p></p>
              <p style="text-align: justify;">
                This study explores how multimedia forensics can enhance visual user-generated content (UGC) verification in journalism by proposing it as a sixth key element alongside the existing five. It provides an overview of visual content forgery types and detection methods from computer science, and maps current verification tools used by media professionals, highlighting their limitations and potential for future development. The goal is to build media practitioners’ trust in integrating multimedia forensics into everyday journalistic workflows.
              </p>
            </td>
          </tr>


        </tbody></table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:16px;width:100%;vertical-align:middle">
            <h2>Conference Papers</h2>
          </td>
        </tr>
      </tbody></table>
      
      <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <!-- <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
              <source src="images/r2r.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div> -->
              <img src='images/r2r.jpg' width=100%>
            </div>
            <!-- <script type="text/javascript">
              function r2r_start() {
                document.getElementById('r2r_image').style.opacity = "1";
              }

              function r2r_stop() {
                document.getElementById('r2r_image').style.opacity = "0";
              }
              r2r_stop()
            </script> -->
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://relight-to-reconstruct.github.io/">
              <span class="papertitle">CLIPping the Deception: Adapting Vision-Language Models for Universal Deepfake Detection
              </span>
            </a>
            <br>
            <strong>Sohail Ahmed Khan</strong>, 
            <a href="https://dnductien.github.io/">Duc-Tien Dang-Nguyen</a>
            <br>
            <em>ACM ICMR</em>, 2024 &nbsp
            <br>
            <a href="https://github.com/sfimediafutures/CLIPping-the-Deception">code</a>
            /
            <a href="https://dl.acm.org/doi/abs/10.1145/3652583.3658035">paper</a>
            <p></p>
            <p style="text-align: justify;">
              We investigate the use of pre-trained vision-language models (VLMs), specifically CLIP, for universal deepfake detection using a single dataset (ProGAN) for adaptation. Unlike prior work that disregards CLIP’s textual component, the authors demonstrate that retaining it significantly boosts performance. Their lightweight Prompt Tuning approach surpasses the previous state-of-the-art by notable margins while using significantly less training data, and proves effective across 21 diverse deepfake datasets.
            </p>
          </td>
        </tr>
        
        <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <!-- <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
              <source src="images/cat4d.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div> -->
              <img src='images/cat4d.jpg' width="160">
            </div>
            <!-- <script type="text/javascript">
              function cat4d_start() {
                document.getElementById('cat4d_image').style.opacity = "1";
              }

              function cat4d_stop() {
                document.getElementById('cat4d_image').style.opacity = "0";
              }
              cat4d_stop()
            </script> -->
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://cat-4d.github.io/">
          <span class="papertitle">Video Transformer for Deepfake Detection with Incremental Learning
          </span>
            </a>
            <br>
            <strong>Sohail Ahmed Khan</strong>,
            <a href="https://dai-hang.github.io/">Hang Dai</a>
            <br>
            <em>ACM Multimedia</em>, 2021 &nbsp
            <!-- <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
            <br>
            <a href="https://github.com/sohailahmedkhan/Video-Transformer-for-Deepfake-Detection">code</a>
            /
            <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475332">paper</a>
            <p></p>
            <p style="text-align: justify;">
              We introduce a novel video transformer model with incremental learning for detecting deepfake videos. It leverages 3D face reconstruction to generate UV texture maps from input face images, using both the textures and original images to extract rich features like pose and facial movements. The model, fine-tuned through incremental learning, achieves state-of-the-art performance across multiple public deepfake datasets.
            </p>
          </td>
        </tr>
      </tbody></table>





          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Invited Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
